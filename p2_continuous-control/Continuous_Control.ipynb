{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "USE_MULTI_AGENT_ENV = True\n",
    "\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')\n",
    "\n",
    "if USE_MULTI_AGENT_ENV:\n",
    "    env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')\n",
    "else:\n",
    "    env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unityagents.brain.BrainParameters at 0x7f1217d7a978>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "# states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "# scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "# counter = 0\n",
    "# print('states', states.shape)\n",
    "# while True:\n",
    "#     counter += 1\n",
    "#     actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "#     actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "#     env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "#     next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "#     rewards = env_info.rewards                         # get reward (for each agent)\n",
    "#     dones = env_info.local_done                        # see if episode finished\n",
    "#     scores += env_info.rewards                         # update the score (for each agent)\n",
    "#     states = next_states                               # roll over states to next time step\n",
    "#     if np.any(dones):                                  # exit loop if episode finished\n",
    "#         break\n",
    "# print('round {}, Total score (averaged over agents) this episode: {}'.format(counter,np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition (Actor & Critic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc_units=256):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc_units)\n",
    "        self.fc2 = nn.Linear(fc_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        return F.tanh(self.fc2(x))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fcs1_units=256, fc2_units=256, fc3_units=128):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fcs1_units)\n",
    "        self.fc2 = nn.Linear(fcs1_units+action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, fc3_units)\n",
    "        self.fc4 = nn.Linear(fc3_units, 1)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "        self.fc4.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        xs = F.leaky_relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        return self.fc4(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Definition (DDPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Definition\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR =  5e-4         # learning rate of the actor \n",
    "LR_CRITIC = 1e-3 #3e-4        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0#0.0001   # L2 weight decay\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, random_seed, warm_up, num_learns_per_step=1, lr_actor=LR_ACTOR):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "        self.warm_up = warm_up\n",
    "        self.num_learns_per_step = num_learns_per_step\n",
    "        print('Agent Initialized with num_learns_per_step=', num_learns_per_step)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=lr_actor)\n",
    "        self.lr_actor = lr_actor\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "        \n",
    "    def set_lr_actor(self, new_lr_actor):\n",
    "        self.lr_actor = new_lr_actor\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=new_lr_actor)\n",
    "    \n",
    "    def act(self, state, add_noise=True):\n",
    "        if USE_MULTI_AGENT_ENV:\n",
    "            return self._act_20(state, add_noise)\n",
    "        else:\n",
    "            return  self._act_single(state, add_noise)\n",
    "            \n",
    "    def step(self, state, action, reward, next_state, done, should_learn=True):\n",
    "        if USE_MULTI_AGENT_ENV:\n",
    "            self._step_20(state, action, reward, next_state, done, should_learn)\n",
    "        else:\n",
    "            self._step_single(state, action, reward, next_state, done)\n",
    "            \n",
    "    def _step_single(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > self.warm_up: \n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "    \n",
    "    def _step_20(self, state_20, action_20, reward_20, next_state_20, done_20, should_learn):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        for i_agent in range(20):\n",
    "            self.memory.add(state_20[i_agent], action_20[i_agent], reward_20[i_agent], next_state_20[i_agent], done_20[i_agent])\n",
    "        if not should_learn:\n",
    "            return\n",
    "        for i_update in range(self.num_learns_per_step):\n",
    "            # Learn, if enough samples are available in memory\n",
    "            if len(self.memory) > self.warm_up: #BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA, do_soft_update= True)\n",
    "\n",
    "    def _act_single(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def _act_20(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        actions_20 = []\n",
    "        with torch.no_grad():\n",
    "            for i_agent in range(20):\n",
    "                action = self.actor_local(state[i_agent].unsqueeze(0)).cpu().data.numpy()\n",
    "                if add_noise:\n",
    "                    action += self.noise.sample()\n",
    "                actions_20.append(action.flatten() )\n",
    "        self.actor_local.train()\n",
    "        actions_20 = np.asarray(actions_20) \n",
    "        return np.clip(actions_20, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma, do_soft_update=True):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        # added clipping, but clipping seems not help, disable\n",
    "        torch.nn.utils.clip_grad_norm(self.critic_local.parameters(), 1)\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        if do_soft_update:\n",
    "            # ----------------------- update target networks ----------------------- #\n",
    "            self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "            self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "        \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to train\n"
     ]
    }
   ],
   "source": [
    "def ddpg(agent, n_episodes, max_t=1000):\n",
    "    model_not_saving = 0\n",
    "    model_not_improving = 0\n",
    "    print('--------start learning----------lr_actor={}; num_step={}'.format(agent.lr_actor, agent.num_learns_per_step))\n",
    "    last_best_score = LAST_BEST_SCORE\n",
    "    last_avg_score = 0\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    num_episodes_over_30 = 0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state_20 = env.reset()[brain_name].vector_observations\n",
    "        agent.reset()\n",
    "        agent_20_avg_score = 0\n",
    "        for t in range(max_t):\n",
    "            # make add_noise=True when early in the training stage;\n",
    "            # I changed it False at the end to verify the agent solves the environemnt\n",
    "            actions_20 = agent.act(state=state_20, add_noise=True) \n",
    "            env_info= env.step(actions_20)[brain_name]\n",
    "            next_states_20 = env_info.vector_observations   # get the next state\n",
    "            reward_20 = env_info.rewards                   # get the reward\n",
    "            done_20 = env_info.local_done \n",
    "            should_learn =  True\n",
    "            if model_not_improving >0 or model_not_saving>1 or last_avg_score > 15 : \n",
    "                should_learn = not (t % 30 < 20)\n",
    "                if model_not_saving > 5:\n",
    "                    should_learn =  not (t % 40 < 30)\n",
    "                if model_not_saving > 10:\n",
    "                    should_learn =  not (t % 60 < 50)\n",
    "            # if model has not been improving, then update the networks 10 times after every 20 timesteps\n",
    "            agent.step(state_20, actions_20, reward_20, next_states_20, done_20, should_learn )\n",
    "            state_20 = next_states_20\n",
    "            agent_20_avg_score += np.mean(reward_20)\n",
    "            if np.any(done_20):\n",
    "                break \n",
    "        scores_deque.append(agent_20_avg_score)\n",
    "        avg_score =  np.mean(scores_deque)\n",
    "        if avg_score <= last_avg_score:\n",
    "            model_not_improving +=1\n",
    "        else:\n",
    "            model_not_improving = 0\n",
    "        last_avg_score = avg_score\n",
    "        final_scores.append(avg_score)\n",
    "        if last_best_score < avg_score:\n",
    "            print('[...Saving model checkpoint with average score] :',avg_score, CHECKPOINT_PATH_ACTOR_TO_WRITE)\n",
    "            last_best_score = avg_score\n",
    "            torch.save(agent.actor_local.state_dict(), CHECKPOINT_PATH_ACTOR_TO_WRITE)\n",
    "            torch.save(agent.critic_local.state_dict(), CHECKPOINT_PATH_CRITIC_TO_WRITE)  \n",
    "            model_not_saving = 0\n",
    "        else:\n",
    "            model_not_saving += 1\n",
    "            \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f} ; model_not_improving {}; model_not_saving {}; Buffer {}.'.format(i_episode, avg_score, model_not_improving,model_not_saving, agent.memory.__len__()))\n",
    "               \n",
    "        if agent_20_avg_score >= 30:\n",
    "            num_episodes_over_30 += 1\n",
    "            if num_episodes_over_30 > 100:\n",
    "                print('\\rSolved environment after {} Episodes\\t Last Average Score: {:.2f}'.format(i_episode+100, avg_score))\n",
    "                return final_scores\n",
    "            \n",
    "        if agent.num_learns_per_step>1 and (model_not_saving >2 or (i_episode >=40 and avg_score <= 15)) :\n",
    "            # reduce learning with each step by half\n",
    "            agent.num_learns_per_step = max(1,int(agent.num_learns_per_step/2))\n",
    "            print('!!reduce num_learns_per_step to {} because model_not_saving {}'.format(agent.num_learns_per_step, model_not_saving))\n",
    "            model_not_saving = 0\n",
    "            \n",
    "        if agent.lr_actor != MIN_LR_ACTOR and (model_not_saving >=15 or model_not_improving >4):\n",
    "            agent.set_lr_actor(max(MIN_LR_ACTOR, agent.lr_actor-1e-5))\n",
    "            print('!! Reduce actor learning rate to:{} because model_not_improving {} or model_not_saving {}'.format(agent.lr_actor, model_not_improving,model_not_saving ))\n",
    "            model_not_improving =0\n",
    "            model_not_saving = 0\n",
    "            \n",
    "        if model_not_improving >5 and model_not_saving >10:\n",
    "            agent.set_lr_actor(1.5e-4)\n",
    "            print('!! Increase actor learning rate to:{} because model_not_improving {} or model_not_saving {}'.format(agent.lr_actor, model_not_improving,model_not_saving ))\n",
    "\n",
    "    print('----- Finish Training for {} Episodes!-------'.format(n_episodes))    \n",
    "    return final_scores\n",
    "print('ready to train')\n",
    "final_scores=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Milestone 1:Training Agent (first 100 episodes)\n",
    "\n",
    "Try 100 episodes first. This is neccessary for the purpose of plotting the whole training process. Wait for first 100 results to ajust hyper paramters otherwise I would have to restart training from scratch everytime. The workspace is never working again after being interrupted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Initialized with num_learns_per_step= 5\n",
      "--------start learning----------\n",
      "Episode 1\tAverage Score: 0.64\n",
      "saving model checkpoint with average score : 0.636499985773\n",
      "Episode 2\tAverage Score: 0.99\n",
      "saving model checkpoint with average score : 0.986999977939\n",
      "Episode 3\tAverage Score: 1.21\n",
      "saving model checkpoint with average score : 1.20849997299\n",
      "Episode 4\tAverage Score: 1.35\n",
      "saving model checkpoint with average score : 1.34587496992\n",
      "Episode 5\tAverage Score: 1.55\n",
      "saving model checkpoint with average score : 1.54859996539\n",
      "Episode 6\tAverage Score: 1.86\n",
      "saving model checkpoint with average score : 1.85533329186\n",
      "Episode 7\tAverage Score: 2.05\n",
      "saving model checkpoint with average score : 2.05378566838\n",
      "Episode 8\tAverage Score: 2.24\n",
      "saving model checkpoint with average score : 2.24087494991\n",
      "Episode 9\tAverage Score: 2.47\n",
      "saving model checkpoint with average score : 2.46927772259\n",
      "Episode 10\tAverage Score: 2.65\n",
      "saving model checkpoint with average score : 2.65489994066\n",
      "Episode 11\tAverage Score: 2.83\n",
      "saving model checkpoint with average score : 2.82631811865\n",
      "Episode 12\tAverage Score: 2.96\n",
      "saving model checkpoint with average score : 2.95816660055\n",
      "Episode 13\tAverage Score: 3.10\n",
      "saving model checkpoint with average score : 3.10457685368\n",
      "Episode 14\tAverage Score: 3.31\n",
      "saving model checkpoint with average score : 3.31182135455\n",
      "Episode 15\tAverage Score: 3.56\n",
      "saving model checkpoint with average score : 3.55626658718\n",
      "Episode 16\tAverage Score: 3.83\n",
      "saving model checkpoint with average score : 3.82896866442\n",
      "Episode 17\tAverage Score: 4.14\n",
      "saving model checkpoint with average score : 4.13626461343\n",
      "Episode 18\tAverage Score: 4.39\n",
      "saving model checkpoint with average score : 4.38783323526\n",
      "Episode 19\tAverage Score: 4.65\n",
      "saving model checkpoint with average score : 4.65152621182\n",
      "Episode 20\tAverage Score: 4.81\n",
      "saving model checkpoint with average score : 4.81092489247\n",
      "Episode 21\tAverage Score: 5.04\n",
      "saving model checkpoint with average score : 5.04197607778\n",
      "Episode 22\tAverage Score: 5.24\n",
      "saving model checkpoint with average score : 5.23604533751\n",
      "Episode 23\tAverage Score: 5.42\n",
      "saving model checkpoint with average score : 5.42110857448\n",
      "Episode 24\tAverage Score: 5.55\n",
      "saving model checkpoint with average score : 5.55320820921\n",
      "Episode 25\tAverage Score: 5.71\n",
      "saving model checkpoint with average score : 5.70669987245\n",
      "Episode 26\tAverage Score: 5.88\n",
      "saving model checkpoint with average score : 5.88415371463\n",
      "Episode 27\tAverage Score: 6.10\n",
      "saving model checkpoint with average score : 6.09516653043\n",
      "Episode 28\tAverage Score: 6.32\n",
      "saving model checkpoint with average score : 6.31841057306\n",
      "Episode 29\tAverage Score: 6.46\n",
      "saving model checkpoint with average score : 6.46046537284\n",
      "Episode 30\tAverage Score: 6.60\n",
      "saving model checkpoint with average score : 6.60106651912\n",
      "Episode 31\tAverage Score: 6.76\n",
      "saving model checkpoint with average score : 6.75551597803\n",
      "Episode 32\tAverage Score: 6.93\n",
      "saving model checkpoint with average score : 6.93229672005\n",
      "Episode 33\tAverage Score: 7.20\n",
      "saving model checkpoint with average score : 7.19957559665\n",
      "updated num_learns_per_step to : 2 660000\n",
      "Episode 34\tAverage Score: 7.31\n",
      "saving model checkpoint with average score : 7.31372042476\n",
      "Episode 35\tAverage Score: 7.45\n",
      "saving model checkpoint with average score : 7.44691411926\n",
      "Episode 36\tAverage Score: 7.60\n",
      "saving model checkpoint with average score : 7.59656927465\n",
      "Episode 37\tAverage Score: 7.73\n",
      "saving model checkpoint with average score : 7.72948631372\n",
      "Episode 38\tAverage Score: 7.83\n",
      "saving model checkpoint with average score : 7.82557877245\n",
      "Episode 39\tAverage Score: 7.93\n",
      "saving model checkpoint with average score : 7.93178187399\n",
      "Episode 40\tAverage Score: 8.10\n",
      "saving model checkpoint with average score : 8.10451231885\n",
      "Episode 41\tAverage Score: 8.24\n",
      "saving model checkpoint with average score : 8.23671932809\n",
      "Episode 42\tAverage Score: 8.30\n",
      "saving model checkpoint with average score : 8.29711886216\n",
      "Episode 43\tAverage Score: 8.45\n",
      "saving model checkpoint with average score : 8.45415097383\n",
      "Episode 44\tAverage Score: 8.53\n",
      "saving model checkpoint with average score : 8.53270435473\n",
      "Episode 45\tAverage Score: 8.65\n",
      "saving model checkpoint with average score : 8.65365536213\n",
      "Episode 46\tAverage Score: 8.71\n",
      "saving model checkpoint with average score : 8.712456327\n",
      "Episode 47\tAverage Score: 8.82\n",
      "saving model checkpoint with average score : 8.81507427105\n",
      "Episode 48\tAverage Score: 8.91\n",
      "saving model checkpoint with average score : 8.9136143841\n",
      "Episode 49\tAverage Score: 8.99\n",
      "saving model checkpoint with average score : 8.99243857451\n",
      "Episode 50\tAverage Score: 9.10\n",
      "saving model checkpoint with average score : 9.10260979654\n",
      "Episode 51\tAverage Score: 9.17\n",
      "saving model checkpoint with average score : 9.16770567744\n",
      "Episode 52\tAverage Score: 9.27\n",
      "saving model checkpoint with average score : 9.26934594666\n",
      "Episode 53\tAverage Score: 9.33\n",
      "saving model checkpoint with average score : 9.32871677262\n",
      "Episode 54\tAverage Score: 9.42\n",
      "saving model checkpoint with average score : 9.41684238211\n",
      "Episode 55\tAverage Score: 9.52\n",
      "saving model checkpoint with average score : 9.52425433257\n",
      "Episode 56\tAverage Score: 9.62\n",
      "saving model checkpoint with average score : 9.61602657078\n",
      "Episode 57\tAverage Score: 9.66\n",
      "saving model checkpoint with average score : 9.65714890695\n",
      "Episode 58\tAverage Score: 9.72\n",
      "saving model checkpoint with average score : 9.71702564488\n",
      "Episode 59\tAverage Score: 9.79\n",
      "saving model checkpoint with average score : 9.79269469637\n",
      "Episode 60\tAverage Score: 9.90\n",
      "saving model checkpoint with average score : 9.8992914454\n",
      "Episode 61\tAverage Score: 10.00\n",
      "saving model checkpoint with average score : 10.0008932191\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 62\tAverage Score: 10.09\n",
      "saving model checkpoint with average score : 10.0866691294\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 63\tAverage Score: 10.18\n",
      "saving model checkpoint with average score : 10.1844442168\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 64\tAverage Score: 10.26\n",
      "saving model checkpoint with average score : 10.2598903957\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 65\tAverage Score: 10.35\n",
      "saving model checkpoint with average score : 10.3516536148\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 66\tAverage Score: 10.44\n",
      "saving model checkpoint with average score : 10.4412497666\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 67\tAverage Score: 10.52\n",
      "saving model checkpoint with average score : 10.5207087201\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 68\tAverage Score: 10.59\n",
      "saving model checkpoint with average score : 10.5867644692\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 69\tAverage Score: 10.67\n",
      "saving model checkpoint with average score : 10.6692678775\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 70\tAverage Score: 10.71\n",
      "saving model checkpoint with average score : 10.7113640463\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 71\tAverage Score: 10.79\n",
      "saving model checkpoint with average score : 10.7937462376\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 72\tAverage Score: 10.88\n",
      "saving model checkpoint with average score : 10.8832567012\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 73\tAverage Score: 10.97\n",
      "saving model checkpoint with average score : 10.9673696179\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 74\tAverage Score: 11.04\n",
      "saving model checkpoint with average score : 11.0397362397\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 75\tAverage Score: 11.09\n",
      "saving model checkpoint with average score : 11.0894330855\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 76\tAverage Score: 11.13\n",
      "saving model checkpoint with average score : 11.1285918565\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 77\tAverage Score: 11.17\n",
      "saving model checkpoint with average score : 11.1687919582\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 78\tAverage Score: 11.20\n",
      "saving model checkpoint with average score : 11.196807442\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 79\tAverage Score: 11.23\n",
      "saving model checkpoint with average score : 11.2257086098\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 80\tAverage Score: 11.28\n",
      "saving model checkpoint with average score : 11.2822809978\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 81\tAverage Score: 11.34\n",
      "saving model checkpoint with average score : 11.3436170304\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 82\tAverage Score: 11.39\n",
      "saving model checkpoint with average score : 11.3894204771\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 83\tAverage Score: 11.42\n",
      "saving model checkpoint with average score : 11.4237648049\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 84\tAverage Score: 11.46\n",
      "saving model checkpoint with average score : 11.4564640296\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 85\tAverage Score: 11.44\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 86\tAverage Score: 11.47\n",
      "saving model checkpoint with average score : 11.4670171856\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 87\tAverage Score: 11.50\n",
      "saving model checkpoint with average score : 11.501367559\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 88\tAverage Score: 11.54\n",
      "saving model checkpoint with average score : 11.5372326967\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 89\tAverage Score: 11.57\n",
      "saving model checkpoint with average score : 11.5707356964\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 90\tAverage Score: 11.61\n",
      "saving model checkpoint with average score : 11.608444185\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 91\tAverage Score: 11.65\n",
      "saving model checkpoint with average score : 11.6454832562\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 92\tAverage Score: 11.66\n",
      "saving model checkpoint with average score : 11.6645051741\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 93\tAverage Score: 11.71\n",
      "saving model checkpoint with average score : 11.706822319\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 94\tAverage Score: 11.73\n",
      "saving model checkpoint with average score : 11.7274039932\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 95\tAverage Score: 11.76\n",
      "saving model checkpoint with average score : 11.7585576319\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 96\tAverage Score: 11.82\n",
      "saving model checkpoint with average score : 11.8170205692\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 97\tAverage Score: 11.86\n",
      "saving model checkpoint with average score : 11.856742003\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 98\tAverage Score: 11.87\n",
      "saving model checkpoint with average score : 11.872540551\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 99\tAverage Score: 11.90\n",
      "saving model checkpoint with average score : 11.9044492289\n",
      "updated num_learns_per_step to : 1 1000000\n",
      "Episode 100\tAverage Score: 11.93\n",
      "saving model checkpoint with average score : 11.9347047332\n",
      "updated num_learns_per_step to : 1 1000000\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(num_learns_per_step=5, warm_up = int(1e2), state_size=brain.vector_observation_space_size, action_size=brain.vector_action_space_size, random_seed=0)\n",
    "from workspace_utils import active_session\n",
    "\n",
    "CHECKPOINT_PATH_ACTOR = 'checkpoint_actor_5_25_v2.pth' # best score 36.7\n",
    "CHECKPOINT_PATH_CRITIC = 'checkpoint_critic_5_25_v2.pth'\n",
    "LAST_BEST_SCORE =0\n",
    "\n",
    "with active_session():\n",
    "    solved_scores = ddpg(n_episodes= 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print scores after first 100 episodes\n",
    "with open('first100.txt', 'w') as filehandle:\n",
    "    for score in final_scores:\n",
    "        filehandle.write('%s,' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot score for Milestone1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f117148eef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(final_scores)+1), final_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2: Resume Training Agent for another 100 episodes\n",
    "- When training from loading snapshot(buffer size is 0), increase warmup threshold to 1e5 to avoid bad updates. Otherwise if continuing (buffer is full) , increase num_learns_per_step to 5 to speed up learning, since in the previous 100 episodes reply buffer should have been updated.\n",
    "- Also if agent has not been learning for 3 episodes, instead of updating network in every timestep, only update 10 times after every 20 timesteps. This way the training can be more stable.\n",
    "- reduce actor learning rate to 1.5e-4\n",
    "- enable clipping for critic local network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_2 = Agent(lr_actor=1.5e-4,num_learns_per_step=1, warm_up = int(3e4), state_size=brain.vector_observation_space_size, action_size=brain.vector_action_space_size, random_seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Initialized with num_learns_per_step= 1\n",
      "*****realoaded saved checkpoint****** checkpoint_actor_5_25_v2.pth checkpoint_critic_5_25_v2.pth\n",
      "--------start learning----------lr_actor=0.00015; num_step=1\n",
      "[...Saving model checkpoint with average score] : 14.8249996686 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 1\tAverage Score: 14.82 ; model_not_improving 0; model_not_saving 0; Buffer 20000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:152: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...Saving model checkpoint with average score] : 14.8477496681 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 2\tAverage Score: 14.85 ; model_not_improving 0; model_not_saving 0; Buffer 40000.\n",
      "Episode 3\tAverage Score: 14.42 ; model_not_improving 1; model_not_saving 1; Buffer 60000.\n",
      "Episode 4\tAverage Score: 14.43 ; model_not_improving 0; model_not_saving 2; Buffer 80000.\n",
      "Episode 5\tAverage Score: 14.50 ; model_not_improving 0; model_not_saving 3; Buffer 100000.\n",
      "Episode 6\tAverage Score: 14.41 ; model_not_improving 1; model_not_saving 4; Buffer 120000.\n",
      "Episode 7\tAverage Score: 14.36 ; model_not_improving 2; model_not_saving 5; Buffer 140000.\n",
      "Episode 8\tAverage Score: 14.73 ; model_not_improving 0; model_not_saving 6; Buffer 160000.\n",
      "Episode 9\tAverage Score: 14.71 ; model_not_improving 1; model_not_saving 7; Buffer 180000.\n",
      "[...Saving model checkpoint with average score] : 15.0495496636 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 10\tAverage Score: 15.05 ; model_not_improving 0; model_not_saving 0; Buffer 200000.\n",
      "[...Saving model checkpoint with average score] : 15.2249087506 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 11\tAverage Score: 15.22 ; model_not_improving 0; model_not_saving 0; Buffer 220000.\n",
      "[...Saving model checkpoint with average score] : 15.3536663235 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 12\tAverage Score: 15.35 ; model_not_improving 0; model_not_saving 0; Buffer 240000.\n",
      "[...Saving model checkpoint with average score] : 15.503538115 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 13\tAverage Score: 15.50 ; model_not_improving 0; model_not_saving 0; Buffer 260000.\n",
      "Episode 14\tAverage Score: 15.49 ; model_not_improving 1; model_not_saving 1; Buffer 280000.\n",
      "Episode 15\tAverage Score: 15.46 ; model_not_improving 2; model_not_saving 2; Buffer 300000.\n",
      "Episode 16\tAverage Score: 15.48 ; model_not_improving 0; model_not_saving 3; Buffer 320000.\n",
      "Episode 17\tAverage Score: 15.50 ; model_not_improving 0; model_not_saving 4; Buffer 340000.\n",
      "[...Saving model checkpoint with average score] : 15.541582986 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 18\tAverage Score: 15.54 ; model_not_improving 0; model_not_saving 0; Buffer 360000.\n",
      "[...Saving model checkpoint with average score] : 15.5570522839 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 19\tAverage Score: 15.56 ; model_not_improving 0; model_not_saving 0; Buffer 380000.\n",
      "[...Saving model checkpoint with average score] : 15.7238996485 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 20\tAverage Score: 15.72 ; model_not_improving 0; model_not_saving 0; Buffer 400000.\n",
      "[...Saving model checkpoint with average score] : 15.8337853604 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 21\tAverage Score: 15.83 ; model_not_improving 0; model_not_saving 0; Buffer 420000.\n",
      "[...Saving model checkpoint with average score] : 15.9091132808 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 22\tAverage Score: 15.91 ; model_not_improving 0; model_not_saving 0; Buffer 440000.\n",
      "[...Saving model checkpoint with average score] : 15.9732605125 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 23\tAverage Score: 15.97 ; model_not_improving 0; model_not_saving 0; Buffer 460000.\n",
      "[...Saving model checkpoint with average score] : 16.0328121416 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 24\tAverage Score: 16.03 ; model_not_improving 0; model_not_saving 0; Buffer 480000.\n",
      "[...Saving model checkpoint with average score] : 16.0952196402 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 25\tAverage Score: 16.10 ; model_not_improving 0; model_not_saving 0; Buffer 500000.\n",
      "[...Saving model checkpoint with average score] : 16.111576563 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 26\tAverage Score: 16.11 ; model_not_improving 0; model_not_saving 0; Buffer 520000.\n",
      "Episode 27\tAverage Score: 16.11 ; model_not_improving 1; model_not_saving 1; Buffer 540000.\n",
      "Episode 28\tAverage Score: 16.10 ; model_not_improving 2; model_not_saving 2; Buffer 560000.\n",
      "[...Saving model checkpoint with average score] : 16.1362065359 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 29\tAverage Score: 16.14 ; model_not_improving 0; model_not_saving 0; Buffer 580000.\n",
      "[...Saving model checkpoint with average score] : 16.1789496384 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 30\tAverage Score: 16.18 ; model_not_improving 0; model_not_saving 0; Buffer 600000.\n",
      "Episode 31\tAverage Score: 16.18 ; model_not_improving 1; model_not_saving 1; Buffer 620000.\n",
      "[...Saving model checkpoint with average score] : 16.2132027626 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 32\tAverage Score: 16.21 ; model_not_improving 0; model_not_saving 0; Buffer 640000.\n",
      "[...Saving model checkpoint with average score] : 16.2218935768 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 33\tAverage Score: 16.22 ; model_not_improving 0; model_not_saving 0; Buffer 660000.\n",
      "[...Saving model checkpoint with average score] : 16.2559996367 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 34\tAverage Score: 16.26 ; model_not_improving 0; model_not_saving 0; Buffer 680000.\n",
      "[...Saving model checkpoint with average score] : 16.3579996344 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 35\tAverage Score: 16.36 ; model_not_improving 0; model_not_saving 0; Buffer 700000.\n",
      "[...Saving model checkpoint with average score] : 16.3905274114 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 36\tAverage Score: 16.39 ; model_not_improving 0; model_not_saving 0; Buffer 720000.\n",
      "[...Saving model checkpoint with average score] : 16.3945131471 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 37\tAverage Score: 16.39 ; model_not_improving 0; model_not_saving 0; Buffer 740000.\n",
      "Episode 38\tAverage Score: 16.39 ; model_not_improving 1; model_not_saving 1; Buffer 760000.\n",
      "Episode 39\tAverage Score: 16.38 ; model_not_improving 2; model_not_saving 2; Buffer 780000.\n",
      "Episode 40\tAverage Score: 16.39 ; model_not_improving 0; model_not_saving 3; Buffer 800000.\n",
      "Episode 41\tAverage Score: 16.38 ; model_not_improving 1; model_not_saving 4; Buffer 820000.\n",
      "[...Saving model checkpoint with average score] : 16.4170115378 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 42\tAverage Score: 16.42 ; model_not_improving 0; model_not_saving 0; Buffer 840000.\n",
      "Episode 43\tAverage Score: 16.40 ; model_not_improving 1; model_not_saving 1; Buffer 860000.\n",
      "Episode 44\tAverage Score: 16.42 ; model_not_improving 0; model_not_saving 2; Buffer 880000.\n",
      "[...Saving model checkpoint with average score] : 16.437544077 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 45\tAverage Score: 16.44 ; model_not_improving 0; model_not_saving 0; Buffer 900000.\n",
      "[...Saving model checkpoint with average score] : 16.4674126754 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 46\tAverage Score: 16.47 ; model_not_improving 0; model_not_saving 0; Buffer 920000.\n",
      "Episode 47\tAverage Score: 16.45 ; model_not_improving 1; model_not_saving 1; Buffer 940000.\n",
      "[...Saving model checkpoint with average score] : 16.5012392145 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 48\tAverage Score: 16.50 ; model_not_improving 0; model_not_saving 0; Buffer 960000.\n",
      "[...Saving model checkpoint with average score] : 16.5227139164 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 49\tAverage Score: 16.52 ; model_not_improving 0; model_not_saving 0; Buffer 980000.\n",
      "[...Saving model checkpoint with average score] : 16.5713896296 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 50\tAverage Score: 16.57 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.5874506096 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 51\tAverage Score: 16.59 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.6688361659 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 52\tAverage Score: 16.67 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.6821977403 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 53\tAverage Score: 16.68 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.7165551819 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 54\tAverage Score: 16.72 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.7681268979 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 55\tAverage Score: 16.77 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.7926514104 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 56\tAverage Score: 16.79 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.8136224312 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 57\tAverage Score: 16.81 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.8468272097 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 58\tAverage Score: 16.85 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.8945843681 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 59\tAverage Score: 16.89 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.9149246219 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 60\tAverage Score: 16.91 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.9187947038 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 61\tAverage Score: 16.92 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 16.9748463948 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 62\tAverage Score: 16.97 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.0055393024 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 63\tAverage Score: 17.01 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.0838433681 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 64\tAverage Score: 17.08 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.129145771 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 65\tAverage Score: 17.13 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.1577874953 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 66\tAverage Score: 17.16 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 67\tAverage Score: 17.16 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.1637422634 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 68\tAverage Score: 17.16 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.1735503408 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 69\tAverage Score: 17.17 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.2002639013 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 70\tAverage Score: 17.20 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.2550559523 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 71\tAverage Score: 17.26 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 72\tAverage Score: 17.25 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.275068107 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 73\tAverage Score: 17.28 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.2948915053 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 74\tAverage Score: 17.29 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.3159729463 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 75\tAverage Score: 17.32 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.3320325073 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 76\tAverage Score: 17.33 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.3445385734 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 77\tAverage Score: 17.34 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.3594547402 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 78\tAverage Score: 17.36 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.3727654345 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 79\tAverage Score: 17.37 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.3836433614 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 80\tAverage Score: 17.38 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 81\tAverage Score: 17.38 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.3965788794 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 82\tAverage Score: 17.40 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.4124694903 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 83\tAverage Score: 17.41 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 84\tAverage Score: 17.41 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.4432054925 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 85\tAverage Score: 17.44 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.4601275167 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 86\tAverage Score: 17.46 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.4866317931 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 87\tAverage Score: 17.49 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.5166927903 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 88\tAverage Score: 17.52 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.5385108439 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 89\tAverage Score: 17.54 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.5829384959 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 90\tAverage Score: 17.58 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 17.6125380679 checkpoint_actor_5_25_v2_phase2_v3.pth\n",
      "Episode 91\tAverage Score: 17.61 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "!!  agent learning too slow, early return to fix agent!\n"
     ]
    }
   ],
   "source": [
    "from workspace_utils import active_session\n",
    "\n",
    "CHECKPOINT_PATH_ACTOR = 'checkpoint_actor_5_25_v2.pth' \n",
    "CHECKPOINT_PATH_CRITIC = 'checkpoint_critic_5_25_v2.pth'\n",
    "CHECKPOINT_PATH_ACTOR_TO_WRITE = 'checkpoint_actor_5_25_v2_phase2_v3.pth' \n",
    "CHECKPOINT_PATH_CRITIC_TO_WRITE = 'checkpoint_critic_5_25_v2_phase2_v3.pth'\n",
    "LAST_BEST_SCORE =11.93\n",
    "MIN_LR_ACTOR = 1e-4\n",
    "\n",
    "def load_checkpoint(agent, actor_path, critic_path):\n",
    "    agent.actor_target.load_state_dict(torch.load(actor_path))\n",
    "    agent.actor_local.load_state_dict(torch.load(actor_path))\n",
    "    agent.critic_local.load_state_dict(torch.load(critic_path))\n",
    "    agent.critic_target.load_state_dict(torch.load(critic_path))\n",
    "    print('*****realoaded saved checkpoint******', actor_path, critic_path)\n",
    "\n",
    "\n",
    "with active_session():\n",
    "    load_checkpoint(agent=agent_2, actor_path=CHECKPOINT_PATH_ACTOR, critic_path=CHECKPOINT_PATH_CRITIC)\n",
    "    solved_scores = ddpg(agent=agent_2, n_episodes= 500) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_phase2 = copy.deepcopy(final_scores)\n",
    "with open('first_phase2.txt', 'w') as filehandle:\n",
    "    for score in final_scores_phase2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot score for Milestone2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1171498c50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(final_scores)+1), final_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone3: Train Agent till reaching score 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****realoaded saved checkpoint****** checkpoint_actor_5_25_v2_phase2_v3.pth checkpoint_critic_5_25_v2_phase2_v3.pth\n",
      "--------start learning----------lr_actor=0.0001; num_step=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:152: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...Saving model checkpoint with average score] : 19.9029995551 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 1\tAverage Score: 19.90 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 2\tAverage Score: 19.77 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "Episode 3\tAverage Score: 19.26 ; model_not_improving 2; model_not_saving 2; Buffer 1000000.\n",
      "Episode 4\tAverage Score: 19.01 ; model_not_improving 3; model_not_saving 3; Buffer 1000000.\n",
      "Episode 5\tAverage Score: 19.34 ; model_not_improving 0; model_not_saving 4; Buffer 1000000.\n",
      "Episode 6\tAverage Score: 19.25 ; model_not_improving 1; model_not_saving 5; Buffer 1000000.\n",
      "Episode 7\tAverage Score: 19.15 ; model_not_improving 2; model_not_saving 6; Buffer 1000000.\n",
      "Episode 8\tAverage Score: 19.40 ; model_not_improving 0; model_not_saving 7; Buffer 1000000.\n",
      "Episode 9\tAverage Score: 19.46 ; model_not_improving 0; model_not_saving 8; Buffer 1000000.\n",
      "Episode 10\tAverage Score: 19.55 ; model_not_improving 0; model_not_saving 9; Buffer 1000000.\n",
      "Episode 11\tAverage Score: 19.63 ; model_not_improving 0; model_not_saving 10; Buffer 1000000.\n",
      "Episode 12\tAverage Score: 19.77 ; model_not_improving 0; model_not_saving 11; Buffer 1000000.\n",
      "Episode 13\tAverage Score: 19.84 ; model_not_improving 0; model_not_saving 12; Buffer 1000000.\n",
      "Episode 14\tAverage Score: 19.82 ; model_not_improving 1; model_not_saving 13; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 19.9644995538 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 15\tAverage Score: 19.96 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.0591245516 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 16\tAverage Score: 20.06 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.147087785 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 17\tAverage Score: 20.15 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 18\tAverage Score: 20.11 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "Episode 19\tAverage Score: 20.07 ; model_not_improving 2; model_not_saving 2; Buffer 1000000.\n",
      "Episode 20\tAverage Score: 20.01 ; model_not_improving 3; model_not_saving 3; Buffer 1000000.\n",
      "Episode 21\tAverage Score: 19.95 ; model_not_improving 4; model_not_saving 4; Buffer 1000000.\n",
      "Episode 22\tAverage Score: 19.91 ; model_not_improving 5; model_not_saving 5; Buffer 1000000.\n",
      "Episode 23\tAverage Score: 19.87 ; model_not_improving 6; model_not_saving 6; Buffer 1000000.\n",
      "Episode 24\tAverage Score: 19.90 ; model_not_improving 0; model_not_saving 7; Buffer 1000000.\n",
      "Episode 25\tAverage Score: 19.90 ; model_not_improving 0; model_not_saving 8; Buffer 1000000.\n",
      "Episode 26\tAverage Score: 19.90 ; model_not_improving 1; model_not_saving 9; Buffer 1000000.\n",
      "Episode 27\tAverage Score: 19.92 ; model_not_improving 0; model_not_saving 10; Buffer 1000000.\n",
      "Episode 28\tAverage Score: 19.94 ; model_not_improving 0; model_not_saving 11; Buffer 1000000.\n",
      "Episode 29\tAverage Score: 19.92 ; model_not_improving 1; model_not_saving 12; Buffer 1000000.\n",
      "Episode 30\tAverage Score: 19.93 ; model_not_improving 0; model_not_saving 13; Buffer 1000000.\n",
      "Episode 31\tAverage Score: 19.97 ; model_not_improving 0; model_not_saving 14; Buffer 1000000.\n",
      "Episode 32\tAverage Score: 19.96 ; model_not_improving 1; model_not_saving 15; Buffer 1000000.\n",
      "Episode 33\tAverage Score: 20.02 ; model_not_improving 0; model_not_saving 16; Buffer 1000000.\n",
      "Episode 34\tAverage Score: 20.01 ; model_not_improving 1; model_not_saving 17; Buffer 1000000.\n",
      "Episode 35\tAverage Score: 20.10 ; model_not_improving 0; model_not_saving 18; Buffer 1000000.\n",
      "Episode 36\tAverage Score: 20.08 ; model_not_improving 1; model_not_saving 19; Buffer 1000000.\n",
      "Episode 37\tAverage Score: 20.10 ; model_not_improving 0; model_not_saving 20; Buffer 1000000.\n",
      "Episode 38\tAverage Score: 20.14 ; model_not_improving 0; model_not_saving 21; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.2101790354 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 39\tAverage Score: 20.21 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.223262048 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 40\tAverage Score: 20.22 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.2581580838 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 41\tAverage Score: 20.26 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.2780590706 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 42\tAverage Score: 20.28 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.3127321041 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 43\tAverage Score: 20.31 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.3869313625 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 44\tAverage Score: 20.39 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.4388328765 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 45\tAverage Score: 20.44 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.4691517164 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 46\tAverage Score: 20.47 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.507871882 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 47\tAverage Score: 20.51 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.5114266249 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 48\tAverage Score: 20.51 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.538254643 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 49\tAverage Score: 20.54 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.5726595402 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 50\tAverage Score: 20.57 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.6096171864 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 51\tAverage Score: 20.61 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.6189995391 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 52\tAverage Score: 20.62 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.6353768973 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 53\tAverage Score: 20.64 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.6851384265 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 54\tAverage Score: 20.69 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.7450813545 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 55\tAverage Score: 20.75 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.7784816784 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 56\tAverage Score: 20.78 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.8474907621 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 57\tAverage Score: 20.85 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.8594047062 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 58\tAverage Score: 20.86 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.8881605501 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 59\tAverage Score: 20.89 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 20.9546661983 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 60\tAverage Score: 20.95 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.0215159236 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 61\tAverage Score: 21.02 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.0791527547 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 62\tAverage Score: 21.08 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.1506661939 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 63\tAverage Score: 21.15 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.1772260892 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 64\tAverage Score: 21.18 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.2099687567 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 65\tAverage Score: 21.21 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.2186434651 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 66\tAverage Score: 21.22 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.2477607191 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 67\tAverage Score: 21.25 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.2890657006 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 68\tAverage Score: 21.29 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.3012386543 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 69\tAverage Score: 21.30 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.3172423807 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 70\tAverage Score: 21.32 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.3361967062 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 71\tAverage Score: 21.34 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 72\tAverage Score: 21.32 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "Episode 73\tAverage Score: 21.32 ; model_not_improving 0; model_not_saving 2; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.3369860096 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 74\tAverage Score: 21.34 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 75\tAverage Score: 21.33 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.3631968909 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 76\tAverage Score: 21.36 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.3925254959 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 77\tAverage Score: 21.39 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.4509482385 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 78\tAverage Score: 21.45 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.4800501528 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 79\tAverage Score: 21.48 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.5395495186 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 80\tAverage Score: 21.54 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.5835859373 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 81\tAverage Score: 21.58 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.6304141507 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 82\tAverage Score: 21.63 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.7001621656 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 83\tAverage Score: 21.70 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.7115054671 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 84\tAverage Score: 21.71 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.7897053953 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 85\tAverage Score: 21.79 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.8171448612 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 86\tAverage Score: 21.82 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.8594592815 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 87\tAverage Score: 21.86 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.9003233741 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 88\tAverage Score: 21.90 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.9504320936 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 89\tAverage Score: 21.95 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.9779550643 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 90\tAverage Score: 21.98 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 21.9942797282 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 91\tAverage Score: 21.99 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.0416625508 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 92\tAverage Score: 22.04 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.0558919801 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 93\tAverage Score: 22.06 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.0893239744 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 94\tAverage Score: 22.09 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.1691047676 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 95\tAverage Score: 22.17 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.2026036704 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 96\tAverage Score: 22.20 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.2128757922 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 97\tAverage Score: 22.21 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.2294535848 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 98\tAverage Score: 22.23 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.2637065731 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 99\tAverage Score: 22.26 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.3075745014 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 100\tAverage Score: 22.31 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.4020044993 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 101\tAverage Score: 22.40 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.4842144974 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 102\tAverage Score: 22.48 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.5578344958 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 103\tAverage Score: 22.56 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.6247344943 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 104\tAverage Score: 22.62 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.682779493 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 105\tAverage Score: 22.68 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.7818844908 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 106\tAverage Score: 22.78 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.8700594888 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 107\tAverage Score: 22.87 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.9020644881 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 108\tAverage Score: 22.90 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 22.9727644865 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 109\tAverage Score: 22.97 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.0347044851 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 110\tAverage Score: 23.03 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.0927644838 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 111\tAverage Score: 23.09 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.1444544827 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 112\tAverage Score: 23.14 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.2026344814 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 113\tAverage Score: 23.20 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.2611894801 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 114\tAverage Score: 23.26 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.2771444797 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 115\tAverage Score: 23.28 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.3118644789 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 116\tAverage Score: 23.31 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.354099478 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 117\tAverage Score: 23.35 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.3944494771 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 118\tAverage Score: 23.39 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.4580194757 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 119\tAverage Score: 23.46 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.5029344747 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 120\tAverage Score: 23.50 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.5516094736 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 121\tAverage Score: 23.55 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.6185244721 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 122\tAverage Score: 23.62 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.6607844711 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 123\tAverage Score: 23.66 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.6917744704 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 124\tAverage Score: 23.69 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.7246544697 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 125\tAverage Score: 23.72 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.7498344691 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 126\tAverage Score: 23.75 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.7835044684 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 127\tAverage Score: 23.78 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.8402144671 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 128\tAverage Score: 23.84 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.8820494662 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 129\tAverage Score: 23.88 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.9271944652 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 130\tAverage Score: 23.93 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 23.9714594642 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 131\tAverage Score: 23.97 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.0411394626 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 132\tAverage Score: 24.04 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.0671294621 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 133\tAverage Score: 24.07 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.1110544611 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 134\tAverage Score: 24.11 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.1262644607 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 135\tAverage Score: 24.13 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.15817446 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 136\tAverage Score: 24.16 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.1889644593 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 137\tAverage Score: 24.19 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.2123194588 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 138\tAverage Score: 24.21 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.2345794583 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 139\tAverage Score: 24.23 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.2875694571 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 140\tAverage Score: 24.29 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.3213844564 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 141\tAverage Score: 24.32 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.3642044554 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 142\tAverage Score: 24.36 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.3803044551 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 143\tAverage Score: 24.38 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.4229344541 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 144\tAverage Score: 24.42 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.4657194531 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 145\tAverage Score: 24.47 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.4833794528 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 146\tAverage Score: 24.48 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.5203194519 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 147\tAverage Score: 24.52 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.5330294516 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 148\tAverage Score: 24.53 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.5531294512 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 149\tAverage Score: 24.55 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.5765194507 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 150\tAverage Score: 24.58 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.6190844497 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 151\tAverage Score: 24.62 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.6330094494 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 152\tAverage Score: 24.63 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.6765394484 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 153\tAverage Score: 24.68 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.694324448 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 154\tAverage Score: 24.69 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 155\tAverage Score: 24.69 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.7143444476 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 156\tAverage Score: 24.71 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 157\tAverage Score: 24.71 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.7258994473 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 158\tAverage Score: 24.73 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.7501344468 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 159\tAverage Score: 24.75 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 160\tAverage Score: 24.71 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "Episode 161\tAverage Score: 24.70 ; model_not_improving 2; model_not_saving 2; Buffer 1000000.\n",
      "Episode 162\tAverage Score: 24.69 ; model_not_improving 3; model_not_saving 3; Buffer 1000000.\n",
      "Episode 163\tAverage Score: 24.68 ; model_not_improving 4; model_not_saving 4; Buffer 1000000.\n",
      "Episode 164\tAverage Score: 24.68 ; model_not_improving 0; model_not_saving 5; Buffer 1000000.\n",
      "Episode 165\tAverage Score: 24.70 ; model_not_improving 0; model_not_saving 6; Buffer 1000000.\n",
      "Episode 166\tAverage Score: 24.72 ; model_not_improving 0; model_not_saving 7; Buffer 1000000.\n",
      "Episode 167\tAverage Score: 24.71 ; model_not_improving 1; model_not_saving 8; Buffer 1000000.\n",
      "Episode 168\tAverage Score: 24.70 ; model_not_improving 2; model_not_saving 9; Buffer 1000000.\n",
      "Episode 169\tAverage Score: 24.69 ; model_not_improving 3; model_not_saving 10; Buffer 1000000.\n",
      "Episode 170\tAverage Score: 24.70 ; model_not_improving 0; model_not_saving 11; Buffer 1000000.\n",
      "Episode 171\tAverage Score: 24.73 ; model_not_improving 0; model_not_saving 12; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.7880244459 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 172\tAverage Score: 24.79 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.8232094452 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 173\tAverage Score: 24.82 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 174\tAverage Score: 24.81 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.8778444439 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 175\tAverage Score: 24.88 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 176\tAverage Score: 24.86 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.8886244437 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 177\tAverage Score: 24.89 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 178\tAverage Score: 24.84 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "Episode 179\tAverage Score: 24.86 ; model_not_improving 0; model_not_saving 2; Buffer 1000000.\n",
      "Episode 180\tAverage Score: 24.85 ; model_not_improving 1; model_not_saving 3; Buffer 1000000.\n",
      "Episode 181\tAverage Score: 24.83 ; model_not_improving 2; model_not_saving 4; Buffer 1000000.\n",
      "Episode 182\tAverage Score: 24.81 ; model_not_improving 3; model_not_saving 5; Buffer 1000000.\n",
      "Episode 183\tAverage Score: 24.77 ; model_not_improving 4; model_not_saving 6; Buffer 1000000.\n",
      "Episode 184\tAverage Score: 24.78 ; model_not_improving 0; model_not_saving 7; Buffer 1000000.\n",
      "Episode 185\tAverage Score: 24.77 ; model_not_improving 1; model_not_saving 8; Buffer 1000000.\n",
      "Episode 186\tAverage Score: 24.72 ; model_not_improving 2; model_not_saving 9; Buffer 1000000.\n",
      "Episode 187\tAverage Score: 24.72 ; model_not_improving 3; model_not_saving 10; Buffer 1000000.\n",
      "Episode 188\tAverage Score: 24.69 ; model_not_improving 4; model_not_saving 11; Buffer 1000000.\n",
      "Episode 189\tAverage Score: 24.66 ; model_not_improving 5; model_not_saving 12; Buffer 1000000.\n",
      "Episode 190\tAverage Score: 24.64 ; model_not_improving 6; model_not_saving 13; Buffer 1000000.\n",
      "!! Increase actor learning rate to:0.00015 because model_not_improving 6 or model_not_saving 13\n",
      "Episode 191\tAverage Score: 24.66 ; model_not_improving 0; model_not_saving 14; Buffer 1000000.\n",
      "Episode 192\tAverage Score: 24.65 ; model_not_improving 1; model_not_saving 15; Buffer 1000000.\n",
      "!! Reduce actor learning rate to:0.00014 because model_not_improving 1 or model_not_saving 15\n",
      "Episode 193\tAverage Score: 24.65 ; model_not_improving 0; model_not_saving 1; Buffer 1000000.\n",
      "Episode 194\tAverage Score: 24.62 ; model_not_improving 1; model_not_saving 2; Buffer 1000000.\n",
      "Episode 195\tAverage Score: 24.59 ; model_not_improving 2; model_not_saving 3; Buffer 1000000.\n",
      "Episode 196\tAverage Score: 24.59 ; model_not_improving 0; model_not_saving 4; Buffer 1000000.\n",
      "Episode 197\tAverage Score: 24.59 ; model_not_improving 0; model_not_saving 5; Buffer 1000000.\n",
      "Episode 198\tAverage Score: 24.61 ; model_not_improving 0; model_not_saving 6; Buffer 1000000.\n",
      "Episode 199\tAverage Score: 24.65 ; model_not_improving 0; model_not_saving 7; Buffer 1000000.\n",
      "Episode 200\tAverage Score: 24.63 ; model_not_improving 1; model_not_saving 8; Buffer 1000000.\n",
      "Episode 201\tAverage Score: 24.58 ; model_not_improving 2; model_not_saving 9; Buffer 1000000.\n",
      "Episode 202\tAverage Score: 24.55 ; model_not_improving 3; model_not_saving 10; Buffer 1000000.\n",
      "Episode 203\tAverage Score: 24.52 ; model_not_improving 4; model_not_saving 11; Buffer 1000000.\n",
      "Episode 204\tAverage Score: 24.48 ; model_not_improving 5; model_not_saving 12; Buffer 1000000.\n",
      "!! Reduce actor learning rate to:0.00013 because model_not_improving 5 or model_not_saving 12\n",
      "Episode 205\tAverage Score: 24.45 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "Episode 206\tAverage Score: 24.38 ; model_not_improving 2; model_not_saving 2; Buffer 1000000.\n",
      "Episode 207\tAverage Score: 24.36 ; model_not_improving 3; model_not_saving 3; Buffer 1000000.\n",
      "Episode 208\tAverage Score: 24.38 ; model_not_improving 0; model_not_saving 4; Buffer 1000000.\n",
      "Episode 209\tAverage Score: 24.37 ; model_not_improving 1; model_not_saving 5; Buffer 1000000.\n",
      "Episode 210\tAverage Score: 24.36 ; model_not_improving 2; model_not_saving 6; Buffer 1000000.\n",
      "Episode 211\tAverage Score: 24.33 ; model_not_improving 3; model_not_saving 7; Buffer 1000000.\n",
      "Episode 212\tAverage Score: 24.30 ; model_not_improving 4; model_not_saving 8; Buffer 1000000.\n",
      "Episode 213\tAverage Score: 24.28 ; model_not_improving 5; model_not_saving 9; Buffer 1000000.\n",
      "!! Reduce actor learning rate to:0.00011999999999999999 because model_not_improving 5 or model_not_saving 9\n",
      "Episode 214\tAverage Score: 24.29 ; model_not_improving 0; model_not_saving 1; Buffer 1000000.\n",
      "Episode 215\tAverage Score: 24.31 ; model_not_improving 0; model_not_saving 2; Buffer 1000000.\n",
      "Episode 216\tAverage Score: 24.31 ; model_not_improving 1; model_not_saving 3; Buffer 1000000.\n",
      "Episode 217\tAverage Score: 24.29 ; model_not_improving 2; model_not_saving 4; Buffer 1000000.\n",
      "Episode 218\tAverage Score: 24.32 ; model_not_improving 0; model_not_saving 5; Buffer 1000000.\n",
      "Episode 219\tAverage Score: 24.31 ; model_not_improving 1; model_not_saving 6; Buffer 1000000.\n",
      "Episode 220\tAverage Score: 24.33 ; model_not_improving 0; model_not_saving 7; Buffer 1000000.\n",
      "Episode 221\tAverage Score: 24.36 ; model_not_improving 0; model_not_saving 8; Buffer 1000000.\n",
      "Episode 222\tAverage Score: 24.36 ; model_not_improving 1; model_not_saving 9; Buffer 1000000.\n",
      "Episode 223\tAverage Score: 24.37 ; model_not_improving 0; model_not_saving 10; Buffer 1000000.\n",
      "Episode 224\tAverage Score: 24.39 ; model_not_improving 0; model_not_saving 11; Buffer 1000000.\n",
      "Episode 225\tAverage Score: 24.42 ; model_not_improving 0; model_not_saving 12; Buffer 1000000.\n",
      "Episode 226\tAverage Score: 24.46 ; model_not_improving 0; model_not_saving 13; Buffer 1000000.\n",
      "Episode 227\tAverage Score: 24.50 ; model_not_improving 0; model_not_saving 14; Buffer 1000000.\n",
      "Episode 228\tAverage Score: 24.49 ; model_not_improving 1; model_not_saving 15; Buffer 1000000.\n",
      "!! Reduce actor learning rate to:0.00010999999999999999 because model_not_improving 1 or model_not_saving 15\n",
      "Episode 229\tAverage Score: 24.54 ; model_not_improving 0; model_not_saving 1; Buffer 1000000.\n",
      "Episode 230\tAverage Score: 24.58 ; model_not_improving 0; model_not_saving 2; Buffer 1000000.\n",
      "Episode 231\tAverage Score: 24.60 ; model_not_improving 0; model_not_saving 3; Buffer 1000000.\n",
      "Episode 232\tAverage Score: 24.60 ; model_not_improving 0; model_not_saving 4; Buffer 1000000.\n",
      "Episode 233\tAverage Score: 24.63 ; model_not_improving 0; model_not_saving 5; Buffer 1000000.\n",
      "Episode 234\tAverage Score: 24.66 ; model_not_improving 0; model_not_saving 6; Buffer 1000000.\n",
      "Episode 235\tAverage Score: 24.72 ; model_not_improving 0; model_not_saving 7; Buffer 1000000.\n",
      "Episode 236\tAverage Score: 24.79 ; model_not_improving 0; model_not_saving 8; Buffer 1000000.\n",
      "Episode 237\tAverage Score: 24.84 ; model_not_improving 0; model_not_saving 9; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.9065944433 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 238\tAverage Score: 24.91 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.965319442 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 239\tAverage Score: 24.97 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 24.9885144415 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 240\tAverage Score: 24.99 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.0342744404 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 241\tAverage Score: 25.03 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.0425244403 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 242\tAverage Score: 25.04 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.0658494397 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 243\tAverage Score: 25.07 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "Episode 244\tAverage Score: 25.07 ; model_not_improving 1; model_not_saving 1; Buffer 1000000.\n",
      "Episode 245\tAverage Score: 25.06 ; model_not_improving 2; model_not_saving 2; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.1080494388 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 246\tAverage Score: 25.11 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.1156494386 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 247\tAverage Score: 25.12 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.1281794383 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 248\tAverage Score: 25.13 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.1727294373 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 249\tAverage Score: 25.17 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.2135694364 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 250\tAverage Score: 25.21 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.2397944358 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 251\tAverage Score: 25.24 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.3033844344 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 252\tAverage Score: 25.30 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.3538994333 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 253\tAverage Score: 25.35 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.4190444318 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 254\tAverage Score: 25.42 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.4615394309 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 255\tAverage Score: 25.46 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.4898544303 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 256\tAverage Score: 25.49 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.5324944293 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 257\tAverage Score: 25.53 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.6078844276 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 258\tAverage Score: 25.61 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.7052094254 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 259\tAverage Score: 25.71 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.8368594225 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 260\tAverage Score: 25.84 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 25.9237494206 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 261\tAverage Score: 25.92 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.0074594187 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 262\tAverage Score: 26.01 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.0537794177 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 263\tAverage Score: 26.05 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.1618094152 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 264\tAverage Score: 26.16 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.2366344136 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 265\tAverage Score: 26.24 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.308694412 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 266\tAverage Score: 26.31 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.3903194101 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 267\tAverage Score: 26.39 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.4949394078 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 268\tAverage Score: 26.49 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.6236494049 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 269\tAverage Score: 26.62 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.7130444029 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 270\tAverage Score: 26.71 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.7955944011 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 271\tAverage Score: 26.80 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.8749593993 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 272\tAverage Score: 26.87 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 26.9030393987 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 273\tAverage Score: 26.90 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.0086993963 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 274\tAverage Score: 27.01 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.0341543957 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 275\tAverage Score: 27.03 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.110589394 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 276\tAverage Score: 27.11 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.1496843932 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 277\tAverage Score: 27.15 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.246284391 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 278\tAverage Score: 27.25 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.29034439 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 279\tAverage Score: 27.29 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.3146493895 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 280\tAverage Score: 27.31 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.4094243874 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 281\tAverage Score: 27.41 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.4751543859 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 282\tAverage Score: 27.48 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.5097593851 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 283\tAverage Score: 27.51 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.5793193836 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 284\tAverage Score: 27.58 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.5984343831 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 285\tAverage Score: 27.60 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.6872043811 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 286\tAverage Score: 27.69 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.7667793794 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 287\tAverage Score: 27.77 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.8651993772 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 288\tAverage Score: 27.87 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 27.9318293757 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 289\tAverage Score: 27.93 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.0256543736 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 290\tAverage Score: 28.03 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.0887643722 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 291\tAverage Score: 28.09 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.1512243708 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 292\tAverage Score: 28.15 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.2377593688 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 293\tAverage Score: 28.24 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.318694367 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 294\tAverage Score: 28.32 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.3767543657 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 295\tAverage Score: 28.38 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.4351443644 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 296\tAverage Score: 28.44 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.5127743627 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 297\tAverage Score: 28.51 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.5685143614 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 298\tAverage Score: 28.57 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.6096593605 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 299\tAverage Score: 28.61 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.6803143589 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 300\tAverage Score: 28.68 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.7465243575 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 301\tAverage Score: 28.75 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.8147843559 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 302\tAverage Score: 28.81 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 28.9276843534 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 303\tAverage Score: 28.93 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.0523843506 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 304\tAverage Score: 29.05 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.1387843487 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 305\tAverage Score: 29.14 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.2309743466 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 306\tAverage Score: 29.23 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.3159743447 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 307\tAverage Score: 29.32 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.3609443437 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 308\tAverage Score: 29.36 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.4249993423 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 309\tAverage Score: 29.42 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.4606043415 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 310\tAverage Score: 29.46 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.52657934 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 311\tAverage Score: 29.53 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.6050293383 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 312\tAverage Score: 29.61 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.6556643371 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 313\tAverage Score: 29.66 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.708539336 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 314\tAverage Score: 29.71 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.7400393353 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 315\tAverage Score: 29.74 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.8192193335 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 316\tAverage Score: 29.82 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.8976143317 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 317\tAverage Score: 29.90 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 29.97636433 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 318\tAverage Score: 29.98 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 30.0423893285 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 319\tAverage Score: 30.04 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "[...Saving model checkpoint with average score] : 30.1174443268 checkpoint_actor_5_25_phase3_v1.pth\n",
      "Episode 320\tAverage Score: 30.12 ; model_not_improving 0; model_not_saving 0; Buffer 1000000.\n",
      "*** agent finished learning with score  30.1174443268\n"
     ]
    }
   ],
   "source": [
    "from workspace_utils import active_session\n",
    "\n",
    "CHECKPOINT_PATH_ACTOR = 'checkpoint_actor_5_25_v2_phase2_v3.pth' \n",
    "CHECKPOINT_PATH_CRITIC = 'checkpoint_critic_5_25_v2_phase2_v3.pth'\n",
    "CHECKPOINT_PATH_ACTOR_TO_WRITE = 'checkpoint_actor_5_25_phase3_v1.pth' \n",
    "CHECKPOINT_PATH_CRITIC_TO_WRITE = 'checkpoint_critic_5_25_phase3_v1.pth'\n",
    "LAST_BEST_SCORE =17.6\n",
    "MIN_LR_ACTOR = 1e-4\n",
    "\n",
    "final_scores=[]\n",
    "\n",
    "with active_session():\n",
    "    load_checkpoint(agent=agent_2, actor_path=CHECKPOINT_PATH_ACTOR, critic_path=CHECKPOINT_PATH_CRITIC)\n",
    "    solved_scores = ddpg(agent=agent_2, n_episodes= 500) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scores to file incase workspace is refreshed\n",
    "with open('first_m3.txt', 'w') as filehandle:\n",
    "    for score in final_scores:\n",
    "        filehandle.write('%s,' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot score for Milestone3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1175afe2b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "# ax = plt.axes()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(final_scores)+1), final_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of 100 episodes reaching score 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Initialized with num_learns_per_step= 1\n",
      "*****realoaded saved checkpoint****** checkpoint_actor_5_25_phase3_v1.pth checkpoint_critic_5_25_phase3_v1.pth\n",
      "--------start learning----------lr_actor=0.0001; num_step=1\n",
      "[...Saving model checkpoint with average score] : 32.9224992641\n",
      "Episode 1\tAverage Score: 32.92 ; model_not_saving 0; num_episodes_over_30 0.\n",
      "[...Saving model checkpoint with average score] : 33.2487492568\n",
      "Episode 2\tAverage Score: 33.25 ; model_not_saving 0; num_episodes_over_30 1.\n",
      "Episode 3\tAverage Score: 32.31 ; model_not_saving 1; num_episodes_over_30 2.\n",
      "Episode 4\tAverage Score: 31.80 ; model_not_saving 2; num_episodes_over_30 3.\n",
      "Episode 5\tAverage Score: 31.30 ; model_not_saving 3; num_episodes_over_30 4.\n",
      "Episode 6\tAverage Score: 31.68 ; model_not_saving 4; num_episodes_over_30 5.\n",
      "Episode 7\tAverage Score: 31.76 ; model_not_saving 5; num_episodes_over_30 6.\n",
      "Episode 8\tAverage Score: 31.65 ; model_not_saving 6; num_episodes_over_30 7.\n",
      "Episode 9\tAverage Score: 31.76 ; model_not_saving 7; num_episodes_over_30 8.\n",
      "Episode 10\tAverage Score: 31.66 ; model_not_saving 8; num_episodes_over_30 9.\n",
      "Episode 11\tAverage Score: 31.69 ; model_not_saving 9; num_episodes_over_30 10.\n",
      "Episode 12\tAverage Score: 31.79 ; model_not_saving 10; num_episodes_over_30 11.\n",
      "Episode 13\tAverage Score: 31.85 ; model_not_saving 11; num_episodes_over_30 12.\n",
      "Episode 14\tAverage Score: 31.86 ; model_not_saving 12; num_episodes_over_30 13.\n",
      "Episode 15\tAverage Score: 31.80 ; model_not_saving 13; num_episodes_over_30 14.\n",
      "Episode 16\tAverage Score: 31.66 ; model_not_saving 14; num_episodes_over_30 15.\n",
      "Episode 17\tAverage Score: 31.60 ; model_not_saving 15; num_episodes_over_30 16.\n",
      "Episode 18\tAverage Score: 31.70 ; model_not_saving 16; num_episodes_over_30 17.\n",
      "Episode 19\tAverage Score: 31.61 ; model_not_saving 17; num_episodes_over_30 18.\n",
      "Episode 20\tAverage Score: 31.61 ; model_not_saving 18; num_episodes_over_30 19.\n",
      "Episode 21\tAverage Score: 31.61 ; model_not_saving 19; num_episodes_over_30 20.\n",
      "Episode 22\tAverage Score: 31.68 ; model_not_saving 20; num_episodes_over_30 21.\n",
      "Episode 23\tAverage Score: 31.72 ; model_not_saving 21; num_episodes_over_30 22.\n",
      "Episode 24\tAverage Score: 31.71 ; model_not_saving 22; num_episodes_over_30 23.\n",
      "Episode 25\tAverage Score: 31.74 ; model_not_saving 23; num_episodes_over_30 24.\n",
      "Episode 26\tAverage Score: 31.80 ; model_not_saving 24; num_episodes_over_30 25.\n",
      "Episode 27\tAverage Score: 31.81 ; model_not_saving 25; num_episodes_over_30 26.\n",
      "Episode 28\tAverage Score: 31.89 ; model_not_saving 26; num_episodes_over_30 27.\n",
      "Episode 29\tAverage Score: 31.80 ; model_not_saving 27; num_episodes_over_30 28.\n",
      "Episode 30\tAverage Score: 31.77 ; model_not_saving 28; num_episodes_over_30 29.\n",
      "Episode 31\tAverage Score: 31.80 ; model_not_saving 29; num_episodes_over_30 30.\n",
      "Episode 32\tAverage Score: 31.79 ; model_not_saving 30; num_episodes_over_30 31.\n",
      "Episode 33\tAverage Score: 31.80 ; model_not_saving 31; num_episodes_over_30 32.\n",
      "Episode 34\tAverage Score: 31.82 ; model_not_saving 32; num_episodes_over_30 33.\n",
      "Episode 35\tAverage Score: 31.77 ; model_not_saving 33; num_episodes_over_30 34.\n",
      "Episode 36\tAverage Score: 31.78 ; model_not_saving 34; num_episodes_over_30 35.\n",
      "Episode 37\tAverage Score: 31.79 ; model_not_saving 35; num_episodes_over_30 36.\n",
      "Episode 38\tAverage Score: 31.77 ; model_not_saving 36; num_episodes_over_30 37.\n",
      "Episode 39\tAverage Score: 31.73 ; model_not_saving 37; num_episodes_over_30 38.\n",
      "Episode 40\tAverage Score: 31.69 ; model_not_saving 38; num_episodes_over_30 39.\n",
      "Episode 41\tAverage Score: 31.68 ; model_not_saving 39; num_episodes_over_30 40.\n",
      "Episode 42\tAverage Score: 31.75 ; model_not_saving 40; num_episodes_over_30 41.\n",
      "Episode 43\tAverage Score: 31.72 ; model_not_saving 41; num_episodes_over_30 42.\n",
      "Episode 44\tAverage Score: 31.70 ; model_not_saving 42; num_episodes_over_30 43.\n",
      "Episode 45\tAverage Score: 31.74 ; model_not_saving 43; num_episodes_over_30 44.\n",
      "Episode 46\tAverage Score: 31.75 ; model_not_saving 44; num_episodes_over_30 45.\n",
      "Episode 47\tAverage Score: 31.76 ; model_not_saving 45; num_episodes_over_30 46.\n",
      "Episode 48\tAverage Score: 31.77 ; model_not_saving 46; num_episodes_over_30 47.\n",
      "Episode 49\tAverage Score: 31.80 ; model_not_saving 47; num_episodes_over_30 48.\n",
      "Episode 50\tAverage Score: 31.82 ; model_not_saving 48; num_episodes_over_30 49.\n",
      "Episode 51\tAverage Score: 31.84 ; model_not_saving 49; num_episodes_over_30 50.\n",
      "Episode 52\tAverage Score: 31.87 ; model_not_saving 50; num_episodes_over_30 51.\n",
      "Episode 53\tAverage Score: 31.87 ; model_not_saving 51; num_episodes_over_30 52.\n",
      "Episode 54\tAverage Score: 31.85 ; model_not_saving 52; num_episodes_over_30 53.\n",
      "Episode 55\tAverage Score: 31.84 ; model_not_saving 53; num_episodes_over_30 54.\n",
      "Episode 56\tAverage Score: 31.84 ; model_not_saving 54; num_episodes_over_30 55.\n",
      "Episode 57\tAverage Score: 31.85 ; model_not_saving 55; num_episodes_over_30 56.\n",
      "Episode 58\tAverage Score: 31.87 ; model_not_saving 56; num_episodes_over_30 57.\n",
      "Episode 59\tAverage Score: 31.87 ; model_not_saving 57; num_episodes_over_30 58.\n",
      "Episode 60\tAverage Score: 31.90 ; model_not_saving 58; num_episodes_over_30 59.\n",
      "Episode 61\tAverage Score: 31.93 ; model_not_saving 59; num_episodes_over_30 60.\n",
      "Episode 62\tAverage Score: 31.95 ; model_not_saving 60; num_episodes_over_30 61.\n",
      "Episode 63\tAverage Score: 31.93 ; model_not_saving 61; num_episodes_over_30 62.\n",
      "Episode 64\tAverage Score: 31.95 ; model_not_saving 62; num_episodes_over_30 63.\n",
      "Episode 65\tAverage Score: 31.93 ; model_not_saving 63; num_episodes_over_30 64.\n",
      "Episode 66\tAverage Score: 31.96 ; model_not_saving 64; num_episodes_over_30 65.\n",
      "Episode 67\tAverage Score: 31.96 ; model_not_saving 65; num_episodes_over_30 66.\n",
      "Episode 68\tAverage Score: 31.95 ; model_not_saving 66; num_episodes_over_30 67.\n",
      "Episode 69\tAverage Score: 31.96 ; model_not_saving 67; num_episodes_over_30 68.\n",
      "Episode 70\tAverage Score: 31.97 ; model_not_saving 68; num_episodes_over_30 69.\n",
      "Episode 71\tAverage Score: 32.01 ; model_not_saving 69; num_episodes_over_30 70.\n",
      "Episode 72\tAverage Score: 32.03 ; model_not_saving 70; num_episodes_over_30 71.\n",
      "Episode 73\tAverage Score: 31.99 ; model_not_saving 71; num_episodes_over_30 72.\n",
      "Episode 74\tAverage Score: 31.96 ; model_not_saving 72; num_episodes_over_30 73.\n",
      "Episode 75\tAverage Score: 31.96 ; model_not_saving 73; num_episodes_over_30 74.\n",
      "Episode 76\tAverage Score: 31.96 ; model_not_saving 74; num_episodes_over_30 75.\n",
      "Episode 77\tAverage Score: 31.96 ; model_not_saving 75; num_episodes_over_30 76.\n",
      "Episode 78\tAverage Score: 31.96 ; model_not_saving 76; num_episodes_over_30 77.\n",
      "Episode 79\tAverage Score: 31.94 ; model_not_saving 77; num_episodes_over_30 78.\n",
      "Episode 80\tAverage Score: 31.92 ; model_not_saving 78; num_episodes_over_30 79.\n",
      "Episode 81\tAverage Score: 31.91 ; model_not_saving 79; num_episodes_over_30 80.\n",
      "Episode 82\tAverage Score: 31.88 ; model_not_saving 80; num_episodes_over_30 81.\n",
      "Episode 83\tAverage Score: 31.87 ; model_not_saving 81; num_episodes_over_30 82.\n",
      "Episode 84\tAverage Score: 31.86 ; model_not_saving 82; num_episodes_over_30 83.\n",
      "Episode 85\tAverage Score: 31.87 ; model_not_saving 83; num_episodes_over_30 84.\n",
      "Episode 86\tAverage Score: 31.88 ; model_not_saving 84; num_episodes_over_30 85.\n",
      "Episode 87\tAverage Score: 31.87 ; model_not_saving 85; num_episodes_over_30 86.\n",
      "Episode 88\tAverage Score: 31.86 ; model_not_saving 86; num_episodes_over_30 87.\n",
      "Episode 89\tAverage Score: 31.85 ; model_not_saving 87; num_episodes_over_30 88.\n",
      "Episode 90\tAverage Score: 31.84 ; model_not_saving 88; num_episodes_over_30 89.\n",
      "Episode 91\tAverage Score: 31.85 ; model_not_saving 89; num_episodes_over_30 90.\n",
      "Episode 92\tAverage Score: 31.86 ; model_not_saving 90; num_episodes_over_30 91.\n",
      "Episode 93\tAverage Score: 31.87 ; model_not_saving 91; num_episodes_over_30 92.\n",
      "Episode 94\tAverage Score: 31.89 ; model_not_saving 92; num_episodes_over_30 93.\n",
      "Episode 95\tAverage Score: 31.89 ; model_not_saving 93; num_episodes_over_30 94.\n",
      "Episode 96\tAverage Score: 31.87 ; model_not_saving 94; num_episodes_over_30 95.\n",
      "Episode 97\tAverage Score: 31.89 ; model_not_saving 95; num_episodes_over_30 96.\n",
      "Episode 98\tAverage Score: 31.88 ; model_not_saving 96; num_episodes_over_30 97.\n",
      "Episode 99\tAverage Score: 31.88 ; model_not_saving 97; num_episodes_over_30 98.\n",
      "Episode 100\tAverage Score: 31.88 ; model_not_saving 98; num_episodes_over_30 99.\n",
      "Episode 101\tAverage Score: 31.88 ; model_not_saving 99; num_episodes_over_30 100.\n",
      "Solved environment after 201 Episodes\t Last Average Score: 31.88\n"
     ]
    }
   ],
   "source": [
    "verify_agent = Agent(lr_actor=1e-4, num_learns_per_step=1, warm_up = int(1e2), state_size=brain.vector_observation_space_size, action_size=brain.vector_action_space_size, random_seed=0)\n",
    "\n",
    "from workspace_utils import active_session\n",
    "verification_scores=[]\n",
    "\n",
    "# using best version of model snapshot with highest score \n",
    "CHECKPOINT_PATH_ACTOR = 'checkpoint_actor_5_25_phase3_v1.pth' \n",
    "CHECKPOINT_PATH_CRITIC = 'checkpoint_critic_5_25_phase3_v1.pth'\n",
    "CHECKPOINT_PATH_ACTOR_VERIFY = 'checkpoint_actor_5_25_verify.pth' \n",
    "CHECKPOINT_PATH_CRITIC_VERIFY = 'checkpoint_critic_5_25_verify.pth'\n",
    "LAST_BEST_SCORE =30.1\n",
    "\n",
    "def ddpg_verify(agent, n_episodes, max_t=1000):\n",
    "    model_not_saving = 0\n",
    "    model_not_improving = 0\n",
    "    print('--------start learning----------lr_actor={}; num_step={}'.format(agent.lr_actor, agent.num_learns_per_step))\n",
    "    last_best_score = LAST_BEST_SCORE\n",
    "    last_avg_score = 0\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    num_episodes_over_30 = 0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state_20 = env.reset()[brain_name].vector_observations\n",
    "        agent.reset()\n",
    "        agent_20_avg_score = 0\n",
    "        for t in range(max_t):\n",
    "            # make add_noise=True when early in the training stage;\n",
    "            # I changed it False at the end to verify the agent solves the environemnt\n",
    "            actions_20 = agent.act(state=state_20, add_noise=True) \n",
    "            env_info= env.step(actions_20)[brain_name]\n",
    "            next_states_20 = env_info.vector_observations   # get the next state\n",
    "            reward_20 = env_info.rewards                   # get the reward\n",
    "            done_20 = env_info.local_done \n",
    "            agent.step(state_20, actions_20, reward_20, next_states_20, done_20, should_learn=False )\n",
    "            state_20 = next_states_20\n",
    "            agent_20_avg_score += np.mean(reward_20)\n",
    "            if np.any(done_20):\n",
    "                break \n",
    "        scores_deque.append(agent_20_avg_score)\n",
    "        avg_score =  np.mean(scores_deque)\n",
    "        if avg_score <= last_avg_score:\n",
    "            model_not_improving +=1\n",
    "        else:\n",
    "            model_not_improving = 0\n",
    "        verification_scores.append(avg_score)\n",
    "        if last_best_score < avg_score:\n",
    "            print('[...Saving model checkpoint with average score] :',avg_score)\n",
    "            last_best_score = avg_score\n",
    "            torch.save(agent.actor_local.state_dict(), CHECKPOINT_PATH_ACTOR_VERIFY)\n",
    "            torch.save(agent.critic_local.state_dict(), CHECKPOINT_PATH_CRITIC_VERIFY)  \n",
    "            model_not_saving = 0\n",
    "        else:\n",
    "            model_not_saving += 1\n",
    "        last_avg_score = avg_score\n",
    "            \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f} ; model_not_saving {}; num_episodes_over_30 {}.'.format(i_episode, avg_score,model_not_saving, num_episodes_over_30))\n",
    "               \n",
    "        if avg_score >= 30:\n",
    "            num_episodes_over_30 += 1\n",
    "            if num_episodes_over_30 > 100:\n",
    "                print('\\rSolved environment after {} Episodes\\t Last Average Score: {:.2f}'.format(i_episode+100, avg_score))\n",
    "                return verification_scores\n",
    "        \n",
    "        if (model_not_saving >10 and avg_score < 30) :\n",
    "            print('!!  agent learning too slow, early return to fix agent!')\n",
    "            return verification_scores\n",
    "    return verification_scores\n",
    "\n",
    "with active_session():\n",
    "    load_checkpoint(agent=verify_agent, actor_path=CHECKPOINT_PATH_ACTOR, critic_path=CHECKPOINT_PATH_CRITIC)\n",
    "    solved_scores = ddpg_verify(agent=verify_agent, n_episodes= 200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1175afe978>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here is the plot for verification scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(verification_scores)+1), verification_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
